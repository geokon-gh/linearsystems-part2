#+TITLE: Linear Systems - Part 2:  Clojure
#+DESCRIPTION: Some linear algebra in Clojure - source at https://github.com/geokon-gh/linearsystems-part2

#+EXPORT_FILE_NAME: index.html
#+HTML_DOCTYPE: html5
#+HTML_LINK_UP: ..
#+HTML_LINK_HOME: ..
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../static/worg.css" />
#+HTML_MATHJAX: path: "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"
#+OPTIONS: html-style:nil
#+OPTIONS: num:nil

* Preface
This is a continuation (with some overlap) of what I have been developing in [[http://geokon-gh.github.io/linearsystems-part1/index.html][Part 1]]. There I had developed a linear algebra system from scratch in ELisp and showed how to use it in several different fundamental applications. However as the algorithms become more complicated, the code started to get a little out of hand. A larger fraction of the time and code was spent on helper functions and extending the system to support different operations I needed and certain design simplifications and errors I had made at the beginning made the ultimate system inflexible and a bit unsatifying to work with.

To carry on working a bit less encumbered with my own mistakes, I've switched over to Clojure and it's default ~core.matrix~ library. This already handles many little details I was lacking in my ELips implementation and as you'll see writing new algorithms will be much smoother. There will still need to be helper functions written, and there are probably places where I misuse the library due to ignorance. If you see any mistakes or room for improvement, please file an issue in the repo

As before, this is an org document and can be tangled into the full Clojure project without the need for any external files. The tangled output will also be tracker in the repository, (but is no necessary is you use Emacs)

Explaining Clojure is outside the scope of this project, but in short you will need to install Java and [[http://leiningen.org/][Leiningen]]. After you have both, you just clone this repository, go into it, and run ~lein run~ to run the project or ~lein repl~ to start an interactive REPL session.

* Project managment
Project management in Clojure is done through a top level ~project.clj~ file which specified project details and the dependencies we will need. In our case it's just ~core.matrix~
#+BEGIN_SRC clojure :results output silent :session :tangle project.clj
(defproject linearsystems-part2 "0.1.0-SNAPSHOT"
  :description "linea-systems in Clojure"
  :url "http://geokon-gh.github.io/linearsystems-part2/index.html"
  :license {:name "Eclipse Public License"
            :url "http://www.eclipse.org/legal/epl-v10.html"}
  :dependencies [
                 [org.clojure/clojure "1.9.0"]
                 [net.mikera/core.matrix "0.62.0"]]
  :main ^:skip-aot linearsystems-part2.core
  :target-path "target/%s"
  :profiles {:uberjar {:aot :all}})

#+END_SRC
The rest of the code will live in ~src/core.clj~ as is the convention (maybe if there is a lot of code or parts to break off, these will be in separate namespaces/files..)
We start by declaring the project namespace and including all of ~core.matrix~. Since we will be using it extensively and I don't want to overload any of its names, I'm not even bothering to alias it.
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (ns linearsystems-part2.core
    (:require [clojure.core.matrix :refer :all])  ;[denisovan.core :as den]
    (:gen-class))

  (defn -main
    "I don't do a whole lot ... yet."
    [& args]
    (println "Hello, World!"))

#+END_SRC
The ~-main~ is just a placeholder for the moment
* Householder QR
An alternate method to build a *QR* matrix is to take a more direct approach like in the *LU* and to zero out columns to build an upper triangular *R*. The difference from the *LU* is that now instead of using row operations to get zeroes we will restrict ourselves to using *elementary reflectors*. Their key property is that they are orthonormal, so when we carry out a series of reflections *Q_{1}Q_{2}..Q_{k}A* we can combine them into one matrix which will be guaranteed to be orthonormal too. In the *LU*'s Gaussian elimination the elementary matrices we used were not  orthonormal so we didn't have this same guarantee (for a simple example consider row-addition: it's not orthogonal and its norm isn't equal to 1)


** elementary reflector
An elementary reflector is a special matrix/linear-system which when given a vector produces its reflection across a hyperplane. The hyperplane is orthogonal to some reference vector *u*. The textbook has a nice illustration for the *R^3* case , but to understand it in higher dimensions you need to break up the problem. The hyperplane you reflect over is the /not-in-span-of/ *u* space. So in effect to get the reflection you are taking the component of your vector that's in the direction of *u* and subtracting it twice to create its reflection. If the input vector is *x* then:
 - *u^{t}x* is the amount of *x* in the direction of *u* (a scalar)
 -  *uu^{t}x* is the vector component in the direction of *u* (a vector)
 -  *uu^{t}x/u^{t}u* is the same vector normalized (a vector)
 -  *x - 2uu^{t}x/u^{t}u* is you subtracting that vector component twice to get the reflection
In matrix form we'd factor out the *x* and get *(I-2uu^{t}/u^{t}u)x*
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn elementary-reflector
    "Build a matrix that will reflect vector across the hyperplane orthogonal to REFLECTION-AXIS"
    [reflection-axis]
    (let [dimension (dimension-count reflection-axis 0)]
      (sub (identity-matrix dimension)
           (mul (outer-product reflection-axis reflection-axis)
                (/ 2 (length-squared reflection-axis))))))
#+END_SRC

** elementary coordinate reflector
To build an upper triangular matrix we need to zero out values below the diagonal. The way we're going to do is by reflecting those columns onto coordinate axis. Ocne a vector is on a coordinate axis then its other components are naturally zero!

So now we would like to take this idea of the reflector matrix a bit further and find a way to construct one that will reflect the input vector straight on to a particular coordinate axis. So it needs to have an orthogonal hyperplane that's right between the vector and coordinate axis. This part is a bit hard to picture, but the equation for the vector orthogonal to the reflection plane is
\begin{equation}
u = x + sign(x_{1})||x||e_{1}
\end{equation}
Here *x* is our vector and *e_{1}* is the coordinate axis onto which we want to reflect. *sign(x)||x||e_{1}* is a vector on the coordinate axis that's stretched out so that it forms a sort of isosceles triangle with *x* (in higher dimension...). Since we want the result to lie on *e_{1}* we want to reflect *x* on the line/hyperplane bisecting this triangle. The bisecting line of a isosceles triangle is perpendicular to its base - so it's perfect for our *u*! And it so happens that the the equation for the base is the equation we have
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn elementary-coordinate-reflector
   "Build a matrix that will reflect the INPUT-VECTOR on to the COORDINATE-AXIS"
   [input-vector coordinate-axis] 
   (let [vector-orthogonal-to-reflection-plane
         (sub input-vector
              (mul coordinate-axis
                   (length input-vector)))]
     (if (zero-matrix? vector-orthogonal-to-reflection-plane)
       ;; degenerate case where the input is on the coordinate axis
       (identity-matrix (dimension-count input-vector 0))
       ;; normal case
       (elementary-reflector vector-orthogonal-to-reflection-plane))))

#+END_SRC

So now we can build matrices that reflect vectors onto an axis. We need to leverage this to build the upper triangluar matrix *R* of the *QR*. If we directly start to zero out things column after column with reflectors like we did in the *LU* case we would get an equation of the form  *Q^{-1}_{k}..Q^{-1}_{2}Q^{-1}_{1}A=R*. For the first column we can already write a *Q^{-1}_{1}* that will clear the terms under the first term
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn first-elementary-coordinate-reflector
    "Build a matrix that will reflect the INPUT-VECTOR on to the first elementary vector [ 1 0 0 .. 0 ]"
    [input-vector]
    (elementary-coordinate-reflector input-vector
                                            (get-row (identity-matrix (dimension-count input-vector 0)) 0)))
#+END_SRC

But the problem is that the subsequent *Q^{-1}_{i}*'s are not as clean as row operations and the column of zeroes will not get preserved between reflections. In other words *Q^{-1}_{1}* will reflect the first column onto *e_{1}*, but then the second reflector *Q^{-1}_{2}* will reflect it away somewhere else and you will lose those zeroes. So we need to be a little more clever here and find a way to write *Q^{-1}_{2}* so that it preserves the column of *Q^{-1}_{1}*

#+BEGIN_QUOTE
*Note*: That *Q^{-1}_{i}* = *Q^{T}_{i}* = *Q_{i}*  b/c *Q_{i}* is a reflector and therefore it's own inverse (reflecting something twice gets your the original back). So *Q^{-1}_{i}* and *Q_{i}* can be used interchangeably.

Furthermore *Q^{-1}* = *(Q_1 Q_2 Q_3 ... Q_n)^{-1}* = *Q^{-1}_{n} ... Q^{-1}_{3} Q^{-1}_{2} Q^{-1}_{1}* \\
But this /does not/ equal *Q* - so you /can not/ use them interchageably

The notation that follows is admittedly a bit less consistent than I'd like - but the algorithm thought be clear nonetheless (*TODO* clean up..)
#+END_QUOTE
/p. 341/ we can write *Q^{-1}_{2}* ( or just *Q_{2}*) using block matrices (Note that the book chooses to confusingly use the letter *R_{i}* where I'm using *Q_{i}*)

\begin{equation}
Q_{2}
=
\begin{bmatrix}
1 & 0\\
0 & S_{ n-1, m-1 }\\
\end{bmatrix}
\end{equation}

When you look at  *Q_{2}(Q_{1}A)* in block matrix form you see that the first column and row of *(Q_{1}A)* is untouched and this new block *S* is multiplied with a /submatrix/ of *Q_{1}A* (which is the *(Q_{1}A)* matrix with the first row/column removed). We choose this *S* to be another reflection matrix which will zero out the first column of that submatrix - which will be in the /second/ column of *Q_{1}A*.

So a pattern start to emerge. You take a matrix *A* then you zero out the first column, then you take a submatrix, zero out its first column and then get the next smaller submatrix, zero out its first column.. etc. What's left to figure out is how to combine everything back together to get the full *Q^{-1}R* matrices we want.

On the next page (342) the book generalizes this trick to any dimension and shows you how to build any given *Q_{i}* matrix but *do not use this!!*. You could build each *Q_{i}* but there is actually a much better way to build *Q^{-1}*

Imagine we were give the full *QR* for the sub-matrix  - lets call it *Q{s}R_{s}*. In other words the smaller matrix *Q_{s}*  could triangularize the sub-matrix of *Q_{1}A*  entirely in one go.  Well with the help of the previous formula we could put it in the place of *S* and build a matrix that represented *Q_{rest}=Q_{k}..Q_{2}*. Then we just multiply with *Q_{1}* to get the full *Q^{-1}* for *A*


\begin{equation}
Q^{-1} = Q_{k} ... Q_{2} Q_{1}
\end{equation}
\begin{equation}
Q^{-1} = Q_{rest} Q_{1}
\end{equation}

\begin{equation}
\begin{bmatrix}
Q_{rest}\\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0\\
0 & Q_{s}\\
\end{bmatrix}
\end{equation}

\begin{equation}
\begin{bmatrix}
Q^{-1}\\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0\\
0 & Q_{s}\\
\end{bmatrix}
\begin{bmatrix}
Q_{1}\\
\end{bmatrix}
\end{equation}


\begin{equation}
\begin{bmatrix}
1 & 0\\
0 & Q_{s}\\
\end{bmatrix}
\begin{bmatrix}
Q_{1}\\
\end{bmatrix}
\begin{bmatrix}
A\\
\end{bmatrix}
=
\begin{bmatrix}
R\\
\end{bmatrix}
\end{equation}

So we just need a simple function to take a *Q_{s}* and pad it with these zeroes to build our *Q_{rest}*
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn raise-rank
    "Add a row and column of zeroes to the top left of a matrix. With a 1 in the top left position (0,0)
    Optionally pass in a RANK variable to pad with that many rows (default: 1)"
    ([input-matrix]
     (raise-rank input-matrix 1))
    ([input-matrix rank]
     (if (zero? rank)
       input-matrix
       (raise-rank
        (join-along 1 (column-matrix (get-column (identity-matrix (inc (row-count input-matrix))) 0))
                    (join-along 0 (row-matrix (zero-vector (column-count input-matrix)))
                                input-matrix))
        (dec rank)))))
#+END_SRC

*R_{s}*, the product of reducing the submatrix *Q_{1}A* can be similarly used to build *R*, however if you break up the *Q_{1}A* into block matrices you will see that the first row of *Q_{1}A* is in effect preserved and needs to be copied over

\begin{equation}
\begin{bmatrix}
1 & 0\\
0 & Q_{s}\\
\end{bmatrix}
\begin{bmatrix}
(Q_{1}A)_{1,1} & (Q_{1}A)_{1,*}\\
(Q_{1}A)_{*,1} & (Q_{1}A)_{s,s}\\
\end{bmatrix}
=
\begin{bmatrix}
(Q_{1}A)_{1,1} & (Q_{1}A)_{1,*}\\
0 & Q_{s}(Q_{1}A)_{s,s}\\
\end{bmatrix}
=
\begin{bmatrix}
(Q_{1}A)_{1,1} & (Q_{1}A)_{1,*}\\
0 & R_{s}\\
\end{bmatrix}
=
\begin{bmatrix}
R\\
\end{bmatrix}
\end{equation}

So we similarly need a little helper function here to "augment" *R_{s}* to *R* but with the first row inserted manually from *Q_{1}A* (done in-code late)
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj

  (defn raise-rank-and-insert-row-column
    "Takes a submatrix and put it's in the lower right corner of a larger matrix.
    The submatrix is 1 row and column smaller.
    First insert a column (size of input-matrix  and then a row (size + 1)"
    [input-matrix insert-column insert-row]
    (join-along 0 (row-matrix insert-row)
                (join-along 1 (column-matrix insert-column)
                            input-matrix)))

  (defn raise-rank-and-insert-row
    "Takes a submatrix and put it's in the lower right corner of a larger matrix.
    The submatrix is 1 row and column smaller
    First insert a column of zeroes and then the passed in row (size + 1)"
        [input-matrix insert-row]
        (raise-rank-and-insert-row-column
         input-matrix
         (zero-vector (column-count input-matrix))
         insert-row))
#+END_SRC

But ofcourse we don't have the *Q_{s}R_{s}* yet, so we need to think of this method recursively. *Q_{s}R_{s}* is just the *Q^{-1}R* of a smaller matrix which we can immediately calculate b/c it's simply the submatrix of *Q_{1}A* and  we have both *Q_{1}* and *A* . Once we have the submatrix, we call this procedure again and again we we will make a new *Q_{1}* - but now for this smaller matrix. Then again we get a *Q_{1}A* for this smaller matrix and keep going over and over - at each step the matrix gets one row and column smaller and at some point you will be left with a single column/row in which case the *Q_{1}* will be the full *Q^{-1}* of *A* and *Q_{1}A = Q^{-1}A = R*. So going up a step you will finally have a  *Q_{s}* and so we know how to build a *Q^{-1}R*. This gives us the *Q_{s}* for the step before that, and we just continue going back and building up our *Q^{-1}R* one submatrix at a time till we are left with the full *Q^{-1}R*

*R* is built up similarly in parallel
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn householder-QR
    "Use reflection matrices to build the QR matrix. Returns a [Q^T R] pair"
    [input-matrix]
    (let [reflector-to-zero-out-first-column
          (first-elementary-coordinate-reflector (get-column input-matrix 0))
          input-matrix-with-first-column-zeroed-out
          (mmul reflector-to-zero-out-first-column input-matrix)]
      (if
          ;; Base Case: We're out of columns/rows to reduce
          ;;            Return the reflector and the reduced column
          (or (= (column-count input-matrix) 1) (= (row-count input-matrix) 1))
          [reflector-to-zero-out-first-column input-matrix-with-first-column-zeroed-out]
          ;; Recursive step: Get the Q^{-1}R of the submatrix
          ;;                 Then and combine it with your reflector and reduced matrix
          (let [submatrix (submatrix
                           input-matrix-with-first-column-zeroed-out
                           1 (dec (row-count input-matrix))
                           1 (dec (column-count input-matrix)))
                [submatrix-Q submatrix-R] (householder-QR submatrix)]
            [(mmul (raise-rank submatrix-Q)
                   reflector-to-zero-out-first-column)
             (raise-rank-and-insert-row submatrix-R
                                        (get-row input-matrix-with-first-column-zeroed-out 0))]))))
#+END_SRC

* Least Squares again
While the new *QR* matrices seem to have some very desirable qualities as compared to the *LU*, one major issue is still outstanding. When we perform Gaussian Elimination the upper and lower triangular matrices directly inform us about how to solve the *Ax=b* system of linear equations. Given an output *b* we can use back/forward substitution to pop out an *x* input that satisfies the system of equations. However with the *QR* the *Q* doesn't really make this same method possible b/c it's not triangular.

This is where we need to remember the Least Squared method we'd used previously. In short when a precise solution doesn't exist we try to minimize the difference between *Ax* and *b* by taking the derivative of *(Ax-b)^2*, setting it equal to zero and solving the new system. We found that in matrix notation this gave us *A^{T}Ax=A^{T}b*. We also say (and it should be intuitively apparent) that this gives the exact solution for *Ax=b* when it exist. Now sticking *QR* in for *A* we get *(QR)^{T}QRx=(QR)^{T}b* -> *R^{T}Q^{T}QRx=R^{T}Q^{T}b* and this is where the orthonormality starts to finally pay off! *Q^{T}=Q^{-1}* so *Q{T}Q = I* and so our equations just becomes *R^{T}Rx=R^{T}Q^{T}b* where the right side will evaluate to some some unit column and the left side will be solvable my back/forward substitution again (b/c *R* and *R^{T}* are triangular)

Notice that we did that all in theoretical equation form and how we've avoided having to actually compute *A^{T}A* completely which is a big advantage considering getting the *QR* is more computationally challenging than doing Gaussian Elimination. Pages 346-350 also enumerate the advantages when it comes to numerical stability and computational complexity. However, the augmented matrix trick from *Exercise 4.6.9* is not mentioned.

* Reduction to Hessenberg Form
The *QR* decomposition has given us a great tool for expressing a linear system in a convenient orthogonal basis. The *Q* is the convenient (unique) orthonormal basis and *R* are the coordinates of *A* in this *Q* basis. However if we rewrite *Ax=b* in terms of the *QR* as *QRx=b* we see that *Rx* is not particularly meaningful on it's own b/c it's multiplying coordinates in one basis with a vector in the standard basis.

Looking back at pages ~254~ - ~255~, it seems we should be able to take our input vector *x*, change it to a convenient basis, put it through our linear system, and then go back to the standard basis we started with. The trick will be to just build this basis so that *A* is in an easier/more-convenient form. 

The text start on page ~350~ suggests getting the linear system into the =Upper-Hessenberg Form=, which is /almost upper triangular/  with just one nonzero subdiagonal. The text states that this is much easier than finding an basis that is fully upper-triangfular - and we will see how the Hessenberg for allows us to have a very convenient recursive block matrix solution. The procedure is very similar to how we did the Householder QR decomposition, but with a small surface level change. Whereas before we reduced the first column with a reflector - ie. *Q_{1}A* - now we just need to also "unreflect" the result to get back to the original standard basis. Fortunately this turns out to be very easy b/c the reflectors are their own inverse so we just need to instead write out *Q_{1}AQ_{1}* as *Q_{1}AQ_{1}*.

The complication here is that if we write a Householder reflection here for *Q_{1}* then the diagonal terms in *A*, ie. *A_{i,i}* will all get multiplied and this is for some reason undesirable (*TODO* Understand why this is a drawback..). If we limit to eliminating the sub-sub-diagonal terms then we can write it in block form and avoid this whole issue

So if
\begin{equation}
Q_{1} =
\begin{bmatrix}
1 & 0\\
0 & Q_{1,sub}\\
\end{bmatrix}
\end{equation}

Then we can write out *Q_{1}AQ_{1}* as:

\begin{equation}
\begin{bmatrix}
1 & 0\\
0 & Q_{1,sub}\\
\end{bmatrix}
\begin{bmatrix}
A_{1,1} & A_{1,*}\\
A_{*,1} & A_{sub}\\
\end{bmatrix}
\begin{bmatrix}
1 & 0\\
0 & Q_{1,sub}\\
\end{bmatrix}
=
\begin{bmatrix}
A_{1,1} & A_{1,*} Q_{1,sub}\\
Q_{1,sub}A_{1,*} & Q_{1,sub} A_{1,*} Q_{1,sub}
\end{bmatrix}
=> =>
\begin{bmatrix}
A_{1,1} & A_{1,*} Q_{1,sub}\\
\begin{bmatrix}
1 \\ 0 \\ .. \\ 0
\end{bmatrix}
 & Q_{1,sub} A_{1,*} Q_{1,sub}
\end{bmatrix}
\end{equation}

As before we are looking to reflect the first column onto a coordinate axis so that we get zeroes. Just here we're leaving the diagonal untouched and reflecting the terms under it. So we want the *Q_{1,sub}A_{1,-}* column block matrix product to turn into *[ 1 0 0 0 .. 0 ]* and we can reuse ~first-elementary-coordinate-reflector~  to get the appropriate *Q_{1,sub}*. Finally reusing ~raise rank~ we can build *Q_{1}*
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn hessenberg-form-first-partial-reflector
    "Builds a matrix that will reduce the first column of INPUT-MATRIX to  Hessenberg Form"
    [input-matrix]
    (if
        ;; Degenerate Case: 1 x 1 matrix
        (or (= (column-count input-matrix) 1) (= (row-count input-matrix) 1))
      [[ 1 ]]
    (let [first-column (get-column input-matrix 0)
          subdiagonal-column (subvector first-column 1 (dec (row-count first-column)))
          orthogonal-reducer (first-elementary-coordinate-reflector subdiagonal-column)]
      (raise-rank orthogonal-reducer))))
#+END_SRC
 Once we've chose our *Q_{1}* we calculate the submatrix *Q_{1} A_{1,*} Q_{1}* and then call the recursively just like last time. Working back up the call stack the matrices are combined pretty much as before. We simply raise the rank of the *Q* matrices and pad the resulting matrices like we did for the resulting *R* matrices before.
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn hessenberg-form-reduction
    "Reduce the INPUT-MATRIX to  Hessenberg Form  - H , using reflectors - P. Result will be in the form [P^T H]"
  [input-matrix]
  (let [reflector-to-zero-out-first-column
        (hessenberg-form-first-partial-reflector input-matrix)
        input-matrix-with-first-column-zeroed-out
        (mmul reflector-to-zero-out-first-column input-matrix (transpose reflector-to-zero-out-first-column))]
    (if
        ;; Base Case: We're out of columns/rows to reduce
        ;;            Return the reflector and the reduced column
        (or (= (column-count input-matrix) 1) (= (row-count input-matrix) 1))
        [reflector-to-zero-out-first-column input-matrix-with-first-column-zeroed-out]
        ;; Recursive step: Get the Q^{-1}R of the submatrix
        ;;                 Then and combine it with your reflector and reduced matrix
        (let [submatrix (submatrix
                         input-matrix-with-first-column-zeroed-out
                         1 (dec (row-count input-matrix))
                         1 (dec (column-count input-matrix)))
              [submatrix-P submatrix-H] ( hessenberg-form-reduction submatrix)]
          [(mmul (raise-rank submatrix-P)
                 reflector-to-zero-out-first-column)
           (raise-rank-and-insert-row-column submatrix-H
                                     (subvector (get-column input-matrix-with-first-column-zeroed-out 0) 1 (dec (row-count input-matrix-with-first-column-zeroed-out)))
                                     (get-row input-matrix-with-first-column-zeroed-out 0))]))))
#+END_SRC
* TODOs
- add some TODOs
* SRC_Block template
#+BEGIN_SRC clojure :results output silent :session :tangle src/linearsystems_part2/core.clj
  (defn matrix-template
"template"
[matrix]
)
#+END_SRC

* End
#+BEGIN_Q^{-1}UOTE
This webpage is generated from an org-document (at ~./index.org~) that also generates all the files described. 

Once opened in Emacs:\\
- ~C-c C-e h h~ generates the webpage  \\
- ~C-c C-v C-t~ exports the code blocks into the appropriate files\\
- ~C-c C-c~     org-babel-execute-src-block
- ~C-c C-v C-b~ org-babel-execute-buffer
#+END_Q^{-1}UOTE
