#+TITLE: MoreLinear \\ Fourier
#+DESCRIPTION: linear algebra methods in Clojure

#+INCLUDE: "../web/config.org"

* Goal
Using the multiplicative properties of complex numbers we find a way to construct an convenient, easily-invertible orthogonal basis. This basis allows us to represent a series of input samples (ie. in an input vector) as the sum of a carefully constructed, independent set of sinusoidals. This basis allows us to carry out a class of operations that are numerically intensive in the standard basis but much quicker in the frequency-basis.

* Complex numbers
Complex numbers are of the form *a+ib* where *i=(-1)^{1/2}* and the factor *b* is known as the imaginary component of the complex number. The pair (a,b) are often referred to as a point on the complex plane.

They have some properties which make they act like 2D coordinates with the /real/ component *a* acting as the /x/ and the /imaginary/ component *b* acting as the /y/:
 - (a+ib) + (c+id) = (a+c) + i(bd)
 - c * (a+ib) = ca +icb 

However unlike 2D [x,y] coordinates, complex numbers can be multiplied:
 - (a+ib) * (c+id) = (ac-bd) + i(ad+bc)

In the [x,y] case multiplication is simply no defined (though you can do dot products and cross products). So points in the complex plane have this extra "feature". As far as I can tell there is no easy way to visualize what the result is for the general case

* The Unit Circle
Given two points on the unit circle (ie. all points who's lenght is equal to 1) we can safely write:
 - (a^2+b^2)^{1/2} = 1 /and therefore/ a^2+b^2 = 1
 - (c^2+d^2)^{1/2} = 1 /and therefore/ c^2+d^2 = 1
As we saw, their product is the point /(ac-bd) + i(ad+bc)/ and its length is:
 - [ (ac-bd)^{2} + (ad+bc)^{2} ]^(1/2)
 - [ a^{2}c^{2}-2acbd+b^{2}d^{2}+a^{2}d^{2}+2adbc+b^{2}c^{2} ]^{1/2}
 - [ a^{2}c^{2}+b^{2}b^{2}+a^{2}d^{d}+b^{2}c^{2} ]^{1/2}
 - [ c^2(a^2+b^2) + d^2(a^2+b^2) ]^(1/2)
Here we can substitute in our equations for the 2 points to see that the length of the product is also equal to 1.

So while the general case is hard to think about, we can at least say that the product of any two points on the unit circle gives us a new point on the unit circle

* Euler's Formula

Combining the definition of /sine/ and /cosine/ with pythagoras' theorem (for the case where the hypotenous is equal to one) gives us the trigonometric identity:
 - cos^{2}(\theta)+sin^{2}(\theta) = 1

Euler's formula tells us that: *(TODO: Exapand on this)*
 - e^{i\theta}=cos(\theta)+isin(\theta)

Which allows us to safely say that the length of /e^{i\theta}/ in the "complex plane" is always equal to /1/. And in fact all points on the unit cirlce can be described with Euler's formula. 
As was shown in the previous section, this means:
 -  || e^{i\theta} * e^{i\omega} || = 1
 You can see this either by substituing in the sine/cosine and viewing it as the product of two complex numbers, or you can add the exponent  /e^{i(\theta+\omega)}/ and reusing the trigonometric identity.

Now notice that if /\omega=2\pi-\theta/ that:
 - e^{i(\theta+\omega)} = e^{i2\pi} = cos(2\pi) + isin(2\pi) = 1 + i0 = 1

Also note that complex conjugate of 
 - e^{i\theta}=cos(\theta)+isin(\theta)
is
 - cos(\theta)-isin(\theta)
Using the trigonometric properties
 - sin(-\theta)=-sin(\theta)
 - cos(-\theta)= cos(\theta)
We can rewrite the conjugate as
 - cos(-\theta) + isin{-\theta) = e^{-\theta}

* The roots of unity

Furthermore if /\alpha=2\pi/n/ then:
 - [e^{i\alpha}]^{n} = e^{in\alpha} = e^{i2\pi} = 1
This tells us that taking the n^{th} root of /1/ has a complex numbers solution! (in addition to the trivial solution of /1/)
 - 1^{1/n} = e^{i2\pi/n}
The typical notation here is to say 
 - \xi = e^{-i2\pi/n}
 - \xi^{n}=1
Then by extension we can also get that:
 - \xi^{n+j} = \xi^{n}\xi^{j} = \xi^{j}
 - \xi^{nk} = [\xi^{n}]^{k} = [e^{-i2\pi}]^k = 1^k = 1

* Fourier series

for any integer value of /k/ we can write this special sum:
 -  1 + \xi^k + \xi^{2k} + ... + \xi^{(n-2)k} + \xi^{(n-1)k}
It has the special property that if it's multiplied by /\xi^k/ we get the same sequence back b/c the last term goes to /\xi^{nk} = 1/ and the remaining terms in effect shift places
 -  \xi^k + \xi^{2k} + \xi^{3k} + ... + \xi^{(n-1)k} + 1
So we can write
 - \xi^k * /fourier-series/ = /fourier-series/
 - \xi^k * /fourier-series/ - /fourier-series/ = 0
 - /fourier-series/ * (\xi^k - 1) = 0
And therefore.. 
 - /fourier-series/  = 0
or (for all values of /k/)
 -  1+\xi^k+\xi^{2k}+...+\xi^{(n-2)k}+\xi^{(n-1)k} = 0

While this is an interesting property, we need to leverage this somehow in constructing an orthogonal basis. The sum can be written out in the form:
 -  [ 1 \xi^k \xi^{2k} ... \xi^{(n-1)k} ] [ 1 1 1 ... 1]^{T}= 0
But to form an orthogonal basis we need a set of vectors who's inner product is zero

* Inner products of complex numbers

The problem is that we don't know how to do inner product with complex numbers yet. Some issues arise when we try our normal inner product.In general given a constant /a/ and the vectors /v/ and /w/ we could write
 - [av][w]^T = a [v][w]^T
But with complex values if you try to do the same you get an inconsistent result. Divide by /i/ and things blow up. Here is an example with of an inner product of /v/ with itself (to for example calculate a 2-norm):
 - 0 < [iv][iv]^{T}=i[v][iv]^{T}= i^2[v][v]^T = - [v][v]^T < 0

Sticking with the norm for now, to do norms of vectors with complex values and to have the whole thing keep working we need to introduce /complex conjugates/ and the idea of a /Hermitian transpose/. If you have a value /a+ib/ then its complex conjugate is /a-ib/ and it's denoted with a^{*}. This value turns out to be useful b/c the product of a comlex number and its complex conjugate gives you a real number:
- (a+ib)(a-ib) = a^2-i^2b^2 = a^2+b^2
Notice how when we want to get the "length" of a real number (ie. its absolute value) we can do [a^2]^{1/2} - and the positive root gives us the length. Well when do it with our complex number
 - [(a+ib)(a+ib)^{*}]^{1/2} = [a^2+b^2]^{1/2}
we get pythagoras and its equal to the length on the complex value on the complex plane. So the answer matches our intuition and when we use complex numbers for instance the roots of unity will always have "length" of 1.

When we deal with vectors we are doing something similar when calculating their 2-norm. Instead of /vv^T/ we now do /vv^{*}/ where v^{*} is the /Hermitian transpose/. It's like the the normal transpose, but all the vector values are replaced with their complex conjugates:
- [ v_1 v_2 v_3 .. v_n ]^{*} = [ v_1^{*} v_2^{*} v_3^{*} .. v_n^{*} ]^{T}
Now the inner product sum looks like this
 - v_{1}v_{1}^{*} + v_{2}v_{2}^{*} + v_{3}v_{3}^{*} .. v_{n}v_{n}^{*}
Each product term is giving you a real value and the sum ends up giving you a real value - so the 2-norm is always real. Furthermore the Hermetian transpose of a real vector is equal to the normal transpose - so this new extension is all "backwards compatible" and works with our purely real systems as well

Coming back to our Eurler's forumla, given a \xi, its complex conjugate is easy to derive using the our trigonometric identities:
 - \xi^{*} = [cos(\theta)+isin(\theta)]^{*} = cos(\theta)-isin(\theta) = cos(-\theta)+isin(-\theta) = \xi^{-1}

Given a series of euler exponents we just take the transpose and flip the sign of the exponent;

 - [ \xi_{1}^{a} \xi_{2}^{b} .. \xi_{n}^{z} ] [ \xi_{1}^{a} \xi_{2}^{b} .. \xi_{n}^{z} ]^{*}
 - [ \xi_{1}^{a} \xi_{2}^{b} .. \xi_{n}^{z} ] [ \xi_{1}^{-a} \xi_{2}^{-b} .. \xi_{n}^{-z} ]^{T}

* Fourier Vectors

We saw previously that
 -  [ 1 \xi^k \xi^{2k} ... \xi^{(n-1)k} ] [ 1 1 1 ... 1]^{T}= 0
But now that we can take inner products of complex vectors we can go a few steps further. Given different values of /k/ - here I choose /r/ and /s/

 - [ 1 \xi^r \xi^{2r} ... \xi^{(n-1)r} ] [ 1 \xi^s \xi^{2s} ... \xi^{(n-1)s} ]^{*}
 - [ 1 \xi^r \xi^{2r} ... \xi^{(n-1)r} ] [ 1 \xi^{-s} \xi^{-2s} ... \xi^{-(n-1)s} ]^{T}
 - 1*1 + \xi^r*\xi^-s + \xi^{2r}*\xi^{-2s} + ... + \xi^{(n-2)r}\xi^{-(n-2)s}} + \xi^{(n-1)r}\xi^{-(n-1)s}
 - 1 + \xi^{r-s} + \xi^{2(r-s)} + ... + \xi^{(n-2)(r-s)} + \xi^{(n-1)(r-s)}
We can factor out the (r-s) exponent
 - (1^{1/(r-s)} + \xi^{1} + \xi^{2} + ... + \xi^{n-2} + \xi^{n-1})^{r-s}
 - (1 + \xi^{1} + \xi^{2} + ... + \xi^{n-2} + \xi^{n-1})^{r-s}
And notice that the inner sum is the fourier series and therefore equal to /0/. So the inner product of two Fourier series is also equal to zero  except when /r=s/. /r=s/ is the case we need for the 2-norm:
 -  [ 1 \xi^k \xi^{2k} ... \xi^{(n-1)k} ]  [ 1 \xi^k \xi^{2k} ... \xi^{(n-1)k} ]^{*}
You can write it out and get zero exponents, but you can also just observe that this is the sum of the 2-norms of the roots of unity. There are /n/ terms and each one is necessarily of length /1/, so the answer will always be /n/ no matter what /k/ you choose

Which is an intuitive answer since the fourier series is a sum of points on the complex unit circle and we have /n/ points. Notice that this conveniently holds true for any exponents. Since the "self" inner product is the square of the 2-norm all fourier vectors have length /n^{1/2}/

* Fourier Matrix

We've jsut shown that the fourier vectors are othogonal as long as the /k/'s are different. So we just choose /k/'s 1 through /n/ and slap them together into a fourier matrix *F*:
| 1 | 1         | 1         | 1     | ..  |
| 1 | \xi       | \xi^2     | \xi^3 | ..  |
| 1 | \xi^2     | \xi^4     | \xi^6 | ..  |
| 1 | \xi^3     | \xi^6     | \xi^9 | ..  |
| 1 | ...       | ...       | ...   | ..  |
| 1 | \xi^{n-1} | \xi^{n-2} | ...   | \xi |

1 - Each column represents different exponents of this starting *n^{th} root of unity* that we called \xi. The second column makes one full rotation, the third makes 2 rotations (hence there will be a /1/ in the middle), the fourth will make 3 rotations and have 2 /1/'s, etc.

2 - Looking at the real components of the columns - there is one constant component (the first column) and then /n/ samples of the /cosine/ function over one oscillation for the second column, /n/ samples over 2 periods for the 3rd column, /n/ samples over 3 periods.. etc.  If your input is over 1 second then this maps to a cosine function of 1Hz, 2Hz, 3Hz, etc.

The complex component will look similar, but with the /sine/ function

3 - Since each series (irrespective of the /k/ exponent) has length /n^{1/2}/, all the columns of *F* can be normalized in one go by dividing the matrix by /n^{1/2}/. The resulting matrix *(1/n^{1/2})F* is now ever better b/c it's orthonormal/unitary. Therefore its inverse is just its Hermitian transpose.

 - [(1/n^{1/2})F]^{-1} = [(1/n^{1/2})F]^{*}
 - F^{-1} = (1/n)F^{*}
Looking at /F*F^{-1}/, the diagonal elements will be the normalized vector norms of the fourier vectors (/1/'s), and the off-diagonal elements are all inner products of orthogonal fourier vectors (/0/'s)

* Frequency Space?

We constructed a very convenient basis that's easily invertible and independent of the input and we can now easily move to the basis and back but it's not exactly what one would imagine as "frequency space" and a few things are unresolved

** How does a sinusoidal look in this basis?

Reusing the trigonometric identities: 
 - sin(-\theta) = -sin(\theta)
 - cos(-\theta) = cos(\theta)
We can carefully pair Euler functions to get back sinusoids
 - *[e^{i\theta} + e^{-i\theta}]/2* = [cos(\theta) + isin(\theta) + cos(-\theta) + isin(-\theta)]/2 = *cos(\theta)*
 - *[e^{i\theta} - e^{-i\theta}]/2* = [cos(\theta) + isin(\theta) - cos(-\theta) - isin(-\theta)]/2 = *sin(\theta)*
replacing /\theta/ with /-2\pi\phi/n/ we can turn this into fourier vector terms:
 - cos(2\pi\phi/n) = [\xi^{-\phi} + \xi^{\phi}]/2
 - cos(2\pi\phi) = n*[\xi^{-\phi} + \xi^{\phi}]/2
 - sin(2\pi\phi/n) = [\xi^{-\phi} - \xi^{\phi}]/2
 - sin(2\pi\phi) = n*[\xi^{-\phi} - \xi^{\phi}]/2
This is a bit goofy b/c we haven't have negative /k/ values. Fortunately b/c these are cyclical functions:
 - sin(-\theta) = sin(2\pi - \theta)
 - cos(-\theta) = cos(2\pi - \theta)
 - e^{-i\theta} = e^{i(2\pi-\theta)}
 - \xi^-k = \xi^{n-k}
So we can rewrite is as:
 - cos(2\pi\phi) = n*[\xi^{n-\phi} + \xi^{\phi}]/2
 - sin(2\pi\phi) = n*[\xi^{n-\phi} - \xi^{\phi}]/2
If /\phi/ is equal to a /k/ value, then this will be equal to a basis vector in our fourier matrix.

For instance if \phi = 3 we can pick an /x/
- x = [ 0 0 n/2 0 0 .. 0 0 n/2 0 0]_{1,n}
So that:
- cos(2\pi * 3) = F^{*}x^{T}

Similarly with the sine function, except:
- y = [ 0 0 -n/2 0 0 .. 0 0 n/2 0 0]_{1,n}
So that:
- sin(2\pi * 3) = F^{*}y^{T}

Now obviously these \xi^{n-\phi} and \xi^{\phi} terms are symmetric. So when looking in our fourier basis (at vectors like the /x/ and /y/ above), we can just look at the first n/2 terms to see the oscillating components of our input. If the input had, in the standard basis, /n/ real values, then in the fourier basis we effectively describe the same input using /n/2/ coordinates of complex vectors (which have real and imaginary components).
** How does a frequency who's period isn't a whole fraction of the sample rate come out in this basis?

How about if /\phi/ is not equal to a /k/ value?

